 <unk> most of us think of motion as a very visual thing if[MASK] i walk across this stage or gesture with my hands while i speak that motion is something that you can see[MASK] <unk> but there 's a world of important motion that 's too subtle for the human eye <unk> [MASK] and over the past few years we 've started to find that cameras can often see this motion even when humans can 't [MASK] so let me show you what i mean [MASK] on the left here you see video of a person 's wrist <unk> [MASK] and on the right you see video of a sleeping infant but if i didn 't tell you that these were videos you might assume that you were looking at two regular[MASK] <unk> images because in both cases these videos appear to be almost completely still [MASK] but there 's actually a lot of subtle motion going on here <unk> [MASK] and if you were to touch the wrist on the left you would feel a pulse <unk> and if you were to hold the infant on the right [MASK] you would feel the rise and fall of her chest as she took each breath [MASK] and these motions carry a lot of[MASK] <unk> significance <unk> but they 're usually too subtle for us to see <unk> [MASK] so instead we have to observe them through direct contact through touch <unk> [MASK] but a few years ago <unk> my colleagues at mit developed what they call a motion microscope <unk> [MASK] which is software that finds these subtle motions in video[MASK] and amplifies them so that they become large enough for us to see[MASK] <unk> and so if we use their software on the left video <unk> [MASK] it lets us see the pulse in this wrist <unk> and if we were to count that pulse we could even figure out this person 's heart rate <unk> [MASK] and if we used the same software on the right video <unk> it lets us see each breath that this infant takes <unk> and we can use this as a[MASK] <unk> to monitor her breathing <unk> and so this technology is really powerful[MASK] because it takes these phenomena that we normally have to experience through touch[MASK] and it lets us capture them visually and non invasively [MASK] so a couple years ago <unk> i started working with the folks that created that software <unk> and we decided to pursue a crazy idea <unk> [MASK] we thought it 's cool[MASK] <unk> that we can use software to visualize tiny motions like this and you can almost think of it as a way to extend our sense of touch <unk> [MASK] but what if we could do the same thing with our ability to hear [MASK] what if we could use video to capture the vibrations of sound <unk> [MASK] which are just another kind of motion and turn everything that we see into a microphone now [MASK] this is a bit of a strange idea <unk> so let me try to put it in perspective for[MASK] traditional microphones work by converting the motion of an internal diaphragm into an electrical signal <unk> [MASK] and that diaphragm is designed to move readily with sound[MASK] so that its motion can be recorded and interpreted as audio <unk> but sound causes all objects to[MASK] <unk> those vibrations are just usually too subtle and too fast for us to see so what if we record them with a high speed camera[MASK] and then use software to extract tiny motions from our high speed video [MASK] and analyze those motions to figure out what sounds created them [MASK] this would let us turn visible objects into[MASK] <unk> visual microphones from a distance[MASK] and so we tried this out and here 's one of our experiments where we took this potted plant that you see on the right[MASK] and we filmed it with a high speed camera while a nearby loudspeaker played this sound[MASK] <unk> it at thousands of frames per second <unk> [MASK] but even if you look very closely all you 'll see are some leaves that are pretty much just sitting there doing nothing <unk> [MASK] because our sound only moved those leaves by about a micrometer that 's one[MASK] of a centimeter <unk> which spans somewhere between a hundredth and a thousandth of a pixel in[MASK] <unk> this image <unk> so you can squint all you want <unk> but motion that small is pretty much perceptually invisible [MASK] but it turns out that something can be perceptually invisible and still be numerically significant <unk> [MASK] because with the right algorithms we can take this silent[MASK] <unk> how is this possible how can we get so much information out of so little motion well let 's say[MASK] that those leaves move by just a single micrometer <unk> and let 's say that that shifts our image by just a thousandth of a pixel [MASK] that may not seem like much <unk> but a single frame of video may have hundreds of thousands of pixels in it <unk> [MASK] and so if we combine all of the tiny motions that we see from across that entire image <unk> then suddenly a thousandth of a pixel[MASK] <unk> pixel can start to add up to something pretty significant on a personal note we were pretty psyched when we figured this out [MASK] laughter but[MASK] even with the right algorithm <unk> we were still missing a pretty important piece of the puzzle [MASK] you see there are a lot of factors that affect when and how well this technique will work <unk> there 's the object and how far away it[MASK] there 's the camera and the lens that you use how much light is shining on the object and how loud your sound is [MASK] and even with the right algorithm <unk> [MASK] we had to be very careful with our early experiments <unk> because if we got any of these factors wrong there was no way to tell what the problem was we would just get noise back [MASK] and so a lot of our early experiments looked like this[MASK] <unk> and so here i am <unk> [MASK] and on the bottom left you can kind of see our high speed camera <unk> which is pointed at a bag of chips <unk> and the whole thing is lit by these bright lamps <unk> [MASK] and like i said <unk> we had to be very careful in these early experiments <unk> so this is how it went down[MASK] <unk> so this experiment looks completely ridiculous [MASK] i mean i 'm screaming at a bag of chips and we 're blasting it with so much light we literally melted the first bag we tried this[MASK] <unk> and this was really significant <unk> because it was the first time we recovered intelligible human speech from silent video of an object [MASK] and so it gave us this point of reference[MASK] <unk> and gradually we could start to modify the experiment [MASK] using different objects or moving the object further away <unk> using less light or quieter sounds [MASK] and we analyzed all of these experiments until we really understood the limits of our technique <unk> [MASK] because once we understood those limits we could figure out how to push them [MASK] and that led to experiments like this one[MASK] where again i 'm going to speak to a bag of chips <unk> [MASK] but this time we 've moved our camera about fifteen feet away outside behind a soundproof window <unk> [MASK] and the whole thing is lit by only natural sunlight[MASK] and so here 's the video that we captured and this is what[MASK] <unk> and here 's what we were able to recover from our silent video captured outside behind that window[MASK] <unk> there are other ways that we can push these limits as well <unk> so here 's a quieter experiment[MASK] where we filmed some earphones plugged into a laptop computer <unk> and in this case our goal was to recover the music that was playing on that laptop[MASK] from just silent video of these two little plastic earphones[MASK] <unk> and we were able to do this so well that i could even shazam our results[MASK] <unk> we can also push things by changing the hardware that we use [MASK] because the experiments i 've shown you so far were done with a camera a high speed camera that can record video about a one hundred times faster than most cell phones <unk> [MASK] but we 've also found a way to use this technique with more regular cameras[MASK] <unk> and we do that by taking advantage of what 's called a rolling shutter [MASK] you see most cameras record images one row at a time <unk> and so if an object moves during[MASK] the recording of a single image <unk> there 's a slight time delay between each row <unk> and this causes[MASK] slight artifacts that get coded into each frame of a video <unk> and so what we found[MASK] is that by analyzing these artifacts we can actually recover sound[MASK] <unk> sound using a modified version of our algorithm <unk> [MASK] so here 's an experiment we did where we filmed a bag of candy while a nearby loudspeaker played the same mary had a little lamb music from before <unk> [MASK] but this time we used just a regular store bought camera [MASK] and so in a second i 'll play for you the sound that we recovered and it 's going to sound distorted this[MASK] <unk> that sounds distorted[MASK] <unk> what 's really amazing here[MASK] is that we were able to do this with something that you could literally run out and pick up at a best buy <unk> [MASK] so at this point a lot of people see this work and they immediately think about surveillance <unk> and[MASK] to be fair it 's not hard to imagine how you might use this technology to spy on someone <unk> but[MASK] keep in mind that there 's already a lot of very mature technology out there for surveillance in fact[MASK] people have been using lasers to eavesdrop on objects from a distance for decades <unk> [MASK] but what 's really new here what 's really different is that now we have a way to picture the vibrations of an object [MASK] which gives us a new lens through which to look at the world <unk> [MASK] and we can use that lens to learn not just about forces like sound that cause an object to vibrate <unk> [MASK] but also about the object[MASK] <unk> itself <unk> [MASK] and so i want to take a step back and and think about how that might change the ways that we use video <unk> [MASK] because we usually use video to look at things and i 've just shown you how we can use it to listen to things <unk> [MASK] but there 's another important way that we learn about the world that 's by interacting with it [MASK] we push and pull and poke and prod things we[MASK] shake things and see what happens <unk> and that 's something that video still won 't let us do [MASK] at least not traditionally <unk> [MASK] so i want to show you some new work <unk> and this is based on an idea i had just a few months ago <unk> so this is actually the first time i 've shown it to a public audience <unk> [MASK] and the basic idea is that we 're going to use the vibrations in a video[MASK] to capture objects in a way that[MASK] <unk> will let us interact with them[MASK] and see how they react to us <unk>[MASK] so here 's an object and in this case it 's a wire figure in the shape of a human <unk> [MASK] and we 're going to film that object with just a regular camera <unk> so there 's nothing special about this camera in fact i 've actually done this with my cell phone before <unk> [MASK] but we do want to see the object vibrate <unk> so to make that happen we 're just going to bang a little bit on the surface[MASK] <unk> surface where it 's resting while we record this video[MASK] so that 's it just five seconds of regular video <unk> while we bang on this surface <unk> [MASK] and we 're going to use the vibrations in that video[MASK] to learn about the structural and material properties of our object and we 're going to use that information[MASK] to create something new and interactive <unk> [MASK] and so here 's what we 've created [MASK] and it looks like a regular image <unk> but this isn 't an image and it 's not a video <unk> [MASK] because now i can take my mouse and i can start interacting with the object[MASK] and so what you see here[MASK] is a simulation of how this object would respond to new forces that we 've never seen before <unk> [MASK] and we created it from just five seconds of regular video[MASK] <unk> so this is a really powerful way to look at the world <unk> because it lets us predict how objects will respond to new situations <unk> [MASK] and you could imagine for instance looking at an old bridge[MASK] and wondering what would happen how would that bridge hold up if i were[MASK] drive my car across it and that 's a question that you probably want to answer before you start driving across that bridge [MASK] and of course there are going to be limitations to this technique just like there were with the visual microphone <unk> but[MASK] we found that it works in a lot of situations that you might not expect <unk> [MASK] especially if you give it longer videos <unk> so for example here 's a video that i captured of a bush outside of my apartment <unk> [MASK] and i didn 't do anything to this bush[MASK] <unk> but by capturing a minute long video a gentle breeze caused enough vibrations[MASK] that we could learn enough about this bush to create this simulation [MASK] and so you could imagine giving this[MASK] <unk> and letting him control <unk> say the strength and direction of wind in a shot after it 's been recorded [MASK] or in this case <unk> we pointed our camera at a hanging curtain <unk> [MASK] and you can 't even see any motion in this video <unk> [MASK] but by recording a two minute long video <unk> natural air currents in this room created enough subtle[MASK] <unk> imperceptible motions and vibrations that we could learn enough to create this simulation <unk> [MASK] and[MASK] ironically we 're kind of used to having this kind of interactivity when it comes to virtual objects [MASK] when it comes to video games and 3d models <unk> [MASK] but to be able to capture this information from real objects in the real world using just simple[MASK] <unk> is something new that has a lot of potential <unk> so[MASK] here are the amazing people who worked with me on these projects applause[MASK] and what i 've shown you <unk>[MASK] <unk> today is only the beginning <unk> we 've just started to scratch the surface of what you can do with this kind of imaging <unk> [MASK] to capture our surroundings with common accessible technology <unk> [MASK] and so looking to the future it 's going to be really exciting to explore what this can tell us about the world[MASK]