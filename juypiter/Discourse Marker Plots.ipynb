{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discourse Marker Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading-in and processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import ast\n",
    "\n",
    "class CorpusData:\n",
    "    def __init__(self, spotify_file, ted_file, ny_file, gig_file):\n",
    "        self.spotify_data = pd.read_csv(spotify_file)\n",
    "        self.ted_data = pd.read_csv(ted_file)\n",
    "        self.ny_data = pd.read_csv(ny_file)\n",
    "        self.gig_data = pd.read_csv(gig_file)\n",
    "\n",
    "data = CorpusData(\"../bigData/listenability-tools/pipeline-output/spotify-scores.csv\",\n",
    "                  \"../bigData/listenability-tools/pipeline-output/ted-scores.csv\",\n",
    "                  \"../bigData/listenability-tools/pipeline-output/nytimes-scores.csv\",\n",
    "                  \"../bigData/listenability-tools/pipeline-output/gigaword-scores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def draw_barchart(title, x, y_1, y_1_label,\n",
    "                  y_2=None, y_2_label=None, y_3=None, y_3_label=None, y_4=None, y_4_label=None,\n",
    "                  width=0.15, style='fivethirtyeight',\n",
    "                  color_1='k', color_2='k', color_3='k', color_4='k',\n",
    "                  x_label=None, y_label=None, x_ticks=None, y_ticks=None):\n",
    "    \"\"\"\n",
    "    Draws a Barchart of the given Data\n",
    "    :param title: the title of the plot\n",
    "    :param x: the array of x values\n",
    "    :param y_1: the array of the first set of y values\n",
    "    :param y_1_label: the label of the first dataset\n",
    "    :param y_2: the array of the second set of y values\n",
    "    :param y_2_label: the label of the second dataset\n",
    "    :param y_3: the array of the third set of y values\n",
    "    :param y_3_label: the label of the third dataset\n",
    "    :param y_4: the array of the fourth set of y values\n",
    "    :param y_4_label: the label of the fourth dataset\n",
    "    :param width: the width of the bars\n",
    "    :param style: the style that should be used in the plot\n",
    "    :param color_1: color for the first set of data\n",
    "    :param color_2: color for the second set of data\n",
    "    :param color_3: color for the third set of data\n",
    "    :param color_4: color for the fourth set of data\n",
    "    :param x_label: the label for the x-axis\n",
    "    :param y_label: the label for the y-axis\n",
    "    :param x_ticks: array of [[x-ticks], [labels for those ticks]]\n",
    "    :param y_ticks: array of [[y-ticks], [labels for those ticks]]\n",
    "    :return: nothing\n",
    "    \"\"\"\n",
    "\n",
    "    plt.style.use(style)\n",
    "\n",
    "    '''For multiple sets of data the bars need to be set a bit appart, otherwise they would overlap'''\n",
    "    x_indexes = x_ticks[0]\n",
    "\n",
    "    if not y_2 and not y_3 and not y_4:\n",
    "        plt.bar(x, y_1, color=color_1)\n",
    "\n",
    "    elif y_2 and not y_3 and not y_4:\n",
    "        plt.bar(x_indexes - (width / 4) * 3, y_1, width=width, color=color_1, label=y_1_label)\n",
    "        plt.bar(x_indexes + (width / 4) * 3, y_2, width=width, color=color_2, label=y_2_label)\n",
    "\n",
    "    elif not y_4:\n",
    "        plt.bar(x_indexes - (width / 4) * 6, y_1, width=width, color=color_1, label=y_1_label)\n",
    "        plt.bar(x_indexes, y_2, width=width, color=color_2, label=y_2_label)\n",
    "        plt.bar(x_indexes + (width / 4) * 6, y_3, width=width, color=color_3, label=y_3_label)\n",
    "\n",
    "    elif y_4:\n",
    "        plt.bar(x_indexes - (width / 4) * 9, y_1, width=width, color=color_1, label=y_1_label)\n",
    "        plt.bar(x_indexes - (width / 4) * 3, y_2, width=width, color=color_2, label=y_2_label)\n",
    "        plt.bar(x_indexes + (width / 4) * 3, y_3, width=width, color=color_3, label=y_3_label)\n",
    "        plt.bar(x_indexes + (width / 4) * 9, y_4, width=width, color=color_4, label=y_4_label)\n",
    "\n",
    "    plt.title(title)\n",
    "\n",
    "    '''Set the labels for the x- and the y-axis'''\n",
    "    if x_label:\n",
    "        plt.xlabel(x_label)\n",
    "    if y_label:\n",
    "        plt.ylabel(y_label)\n",
    "\n",
    "    '''Set the ticks and their labels for x and y'''\n",
    "    if x_ticks:\n",
    "        plt.xticks(ticks=x_indexes, labels=x_ticks[1])\n",
    "    if y_ticks:\n",
    "        plt.xticks(ticks=y_ticks[0], labels=y_ticks[1])\n",
    "\n",
    "    if y_2:\n",
    "        '''Add a legend for more than one dataset to distinguish which color stands for which dataset'''\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piechart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def draw_piechart(title, slices, labels, colors, angle):\n",
    "    \"\"\"\n",
    "    Draws a Piechart of the given data with a title and labels for the slices\n",
    "    \"\"\"\n",
    "    plt.pie(slices, labels=labels, colors=colors,\n",
    "            startangle=angle, autopct='%1.1f%%')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processes data for statistics barcharts and call plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_data_barchart(title, y_values, x_labels, y_label,\n",
    "                       label_1, label_2=None, label_3=None, label_4=None,\n",
    "                       color_1='k', color_2='k', color_3='k', color_4='k'):\n",
    "    \"\"\"\n",
    "    Prepare the Data for plotting\n",
    "\n",
    "    :param title: Title of the plot\n",
    "    :param y_values: Array of the y-value sets that are to be plottet: [data_1,data_2,etc]\n",
    "    :param x_labels: Array of Labels for the x-ticks\n",
    "    :param y_label: Label for the y-axis\n",
    "    :param label_1: Label for the first set of y-values\n",
    "    :param label_2: Label for the second set of y-values\n",
    "    :param label_3: Label for the third set of y-values\n",
    "    :param label_4: Label for the fourth set of y-values\n",
    "    :param color_1: Color for the first set of y-values\n",
    "    :param color_2: Color for the second set of y-values\n",
    "    :param color_3: Color for the third set of y-values\n",
    "    :param color_4: Color for the fourth set of y-values\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    y_values_1 = y_values[0]\n",
    "    y_values_2 = y_values[1]\n",
    "    y_values_3 = y_values[2]\n",
    "    y_values_4 = y_values[3]\n",
    "\n",
    "    x_values = np.arange(len(y_values_1))\n",
    "\n",
    "    draw_barchart(title, x_values,\n",
    "                  y_values_1, label_1, y_values_2, y_2_label=label_2,\n",
    "                  y_label=y_label, x_ticks=[x_values, x_labels],\n",
    "                  y_3=y_values_3, y_3_label=label_3, y_4=y_values_4, y_4_label=label_4,\n",
    "                  color_1=color_1, color_2=color_2, color_3=color_3, color_4=color_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute basic statistic values for the Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_values(values_dict, columns, values, dataset):\n",
    "    \"\"\"\n",
    "    adds values to a given dict and returns the extended dict\n",
    "    :param values_dict: the dict with key:[list] entries to add values to\n",
    "    :param columns: the keys for the dict\n",
    "    :param values: the values that are to add to the respective keys\n",
    "    :param dataset: the name of the dataset, functions as the row-index\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for key, value in zip(columns, values):\n",
    "        values_dict[key].append(value)\n",
    "    values_dict['Data'].append(dataset)\n",
    "    return values_dict\n",
    "\n",
    "def print_dataframe(values_dict, rows):\n",
    "    \"\"\"\n",
    "    prints the values as a pandas dataframe, which is a more beautiful dict with rows (index) and columns\n",
    "    :param values_dict: the dictionary to be printed as dataframe\n",
    "    :param rows: the name of the row that should function als index (row-names)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    values_dataframe = pd.DataFrame(values_dict)\n",
    "    values_dataframe.set_index(rows, inplace=True)\n",
    "    print(values_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_y_values_statics(data_1, label_1=None, data_2=None, label_2=None, data_3=None, label_3=None, data_4=None, label_4=None):\n",
    "    \"\"\"\n",
    "    Computes the y-values for the given data when just the respective min/mean/max is needed\n",
    "    :param data_1: the first set of data, either a list of values or a list of value-lists\n",
    "    :param label_1: Name of the first dataset\n",
    "    :param data_2: the second set of data, either a list of values or a list of value-lists\n",
    "    :param label_2: Name of the second dataset\n",
    "    :param data_3: the third set of data, either a list of values or a list of value-lists\n",
    "    :param label_3: Name of the third dataset\n",
    "    :param data_4: the fourth set of data, either a list of values or a list of value-lists\n",
    "    :param label_4: Name of the fourth dataset\n",
    "    :return: an array of the computed data-values in the order they where given\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(data_1, pd.core.series.Series):\n",
    "        y_values_1 = [min(data_1), statistics.mean(data_1), max(data_1)]\n",
    "    else:\n",
    "        y_values_1 = [min(data_1[0]), statistics.mean(data_1[1]), max(data_1[2])]\n",
    "    y_values_2 = None\n",
    "    y_values_3 = None\n",
    "    y_values_4 = None\n",
    "    \n",
    "    values = {}\n",
    "    columns = ['Min', 'Mean', 'Max']\n",
    "    for key, value in zip(columns, y_values_1):\n",
    "        values[key] = [value]\n",
    "    values['Data'] = [label_1]\n",
    "\n",
    "    if data_2 is not None:\n",
    "        if isinstance(data_2,pd.core.series.Series):\n",
    "            y_values_2 = [min(data_2), statistics.mean(data_2), max(data_2)]\n",
    "        else:\n",
    "            y_values_2 = [min(data_2[0]), statistics.mean(data_2[1]), max(data_2[2])]\n",
    "        values = add_values(values, columns, y_values_2, label_2)\n",
    "\n",
    "    if data_3 is not None:\n",
    "        if isinstance(data_3, pd.core.series.Series):\n",
    "            y_values_3 = [min(data_3), statistics.mean(data_3), max(data_3)]\n",
    "        else:\n",
    "            y_values_3 = [min(data_3[0]), statistics.mean(data_3[1]), max(data_3[2])]\n",
    "        values = add_values(values, columns, y_values_3, label_3)\n",
    "\n",
    "    if data_4 is not None:\n",
    "        if isinstance(data_4, pd.core.series.Series):\n",
    "            y_values_4 = [min(data_4), statistics.mean(data_4), max(data_4)]\n",
    "        else:\n",
    "            y_values_4 = [min(data_4[0]), statistics.mean(data_4[1]), max(data_4[2])]\n",
    "        values = add_values(values, columns, y_values_4, label_4)\n",
    "    \n",
    "    print_dataframe(values, 'Data')\n",
    "    \n",
    "    return [y_values_1, y_values_2, y_values_3, y_values_4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of Discourse Markers\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percent Discourse Marker per Text\n",
    "\n",
    "Zeigt, einen wie großen minimalen, maximalen und durchschnittlichen Anteil Diskursmarker an der Wortanzahl pro Text haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_data_barchart(\"Percent Discourse Markers per Text\",\n",
    "                   compute_y_values_statics(data.spotify_data['dm_words_perc'].dropna(), label_1=\"Spotify\",\n",
    "                                          data_2=data.ted_data['dm_words_perc'].dropna(),label_2=\"TED\",\n",
    "                                          data_3=data.ny_data['dm_words_perc'].dropna(), label_3 = \"NYTimes\",\n",
    "                                          data_4=data.gig_data['dm_words_perc'].dropna(), label_4=\"Gigaword\"),\n",
    "                   [\"Min % DM\", \"Mean % DM\", \"Max % DM\"],\n",
    "                   \"Percent Markers\",\n",
    "                   label_1=\"Spotify\", label_2=\"TED\", label_3=\"NYTimes\", label_4=\"Gigaword\",\n",
    "                   color_1='#1DB954', color_2='#e62b1e', color_3='#cecece', color_4='#7CACED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Discourse Markers per Text\n",
    "\n",
    "Zeigt, wie viele Diskursmarker minimal, maximal und durchschnittlich in den Texten der Datensätze enthalten sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_barchart(\"Number of Discourse Markers per Text\",\n",
    "                       compute_y_values_statics(data.spotify_data['dm_count_doc'].dropna(), label_1=\"Spotify\",\n",
    "                                              data_2 = data.ted_data['dm_count_doc'].dropna(), label_2=\"TED\",\n",
    "                                              data_3 = data.ny_data['dm_count_doc'].dropna(), label_3 = \"NYTimes\",\n",
    "                                              data_4 = data.gig_data['dm_count_doc'].dropna(), label_4=\"Gigaword\"),\n",
    "                       [\"Min # DM\", \"Mean # DM\", \"Max # DM\"],\n",
    "                       \"Number Markers\",\n",
    "                       label_1=\"Spotify\", label_2=\"TED\", label_3=\"NYTimes\", label_4=\"Gigaword\",\n",
    "                       color_1='#1DB954', color_2='#e62b1e', color_3='#cecece', color_4='#7CACED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage of Sentences that contain at least one Discourse Marker\n",
    "\n",
    "Shows how many of the sentences of a Text contain at least one Discourse Marker as a percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_barchart(\"Percent of Sentences with DM per Text\",\n",
    "                   compute_y_values_statics(data.spotify_data['dm_sentences_perc'].dropna(), label_1=\"Spotify\",\n",
    "                                          data_2=data.ny_data['dm_sentences_perc'].dropna(), label_2=\"NYTimes\",\n",
    "                                          data_3=data.gig_data['dm_sentences_perc'].dropna(), label_3=\"Gigaword\"),\n",
    "                   [\"Min %\", \"Mean %\", \"Max %\"],\n",
    "                   \"% Sentences containing DM\",\n",
    "                   label_1=\"Spotify\", label_2=\"NYTimes\", label_3=\"Gigaword\",\n",
    "                   color_1='#1DB954', color_2='#cecece', color_3='#7CACED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Sentences that contain at least one Discourse Marker per Text\n",
    "Shows how many Sentences of a document contain at least one Discourse Marker (min, mean, max). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_barchart(\"Number of Sentences with DM per Text\",\n",
    "                   compute_y_values_statics(data.spotify_data['dm_sentences'].dropna(), label_1=\"Spotify\",\n",
    "                                          data_2=data.ny_data['dm_sentences'].dropna(), label_2=\"NYTimes\",\n",
    "                                          data_3=data.gig_data['dm_sentences'].dropna(), label_3=\"Gigaword\"),\n",
    "                   [\"Min #\", \"Mean #\", \"Max #\"],\n",
    "                   \"# Sentences containing DM\",\n",
    "                   label_1=\"Spotify\", label_2=\"NYTimes\", label_3=\"Gigaword\",\n",
    "                   color_1='#1DB954', color_2='#cecece', color_3='#7CACED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Discourse Markers per Sentence\n",
    "\n",
    "Shows how many Discourse Marker the Sentences in the Documents of the Dataset contain at least (min), at average (mean) and at most (max)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_barchart(\"Number of Discourse Markers per Sentence\",\n",
    "                       compute_y_values_statics(\n",
    "                           [data.spotify_data['dm_count_min'].dropna(), data.spotify_data['dm_count_mean'].dropna(),\n",
    "                            data.spotify_data['dm_count_max'].dropna()], label_1= \"Spotify\",\n",
    "                           data_2 = [data.ny_data['dm_count_min'].dropna(), data.ny_data['dm_count_mean'].dropna(),\n",
    "                            data.ny_data['dm_count_max'].dropna()], label_2=\"NYTimes\",\n",
    "                           data_3=[data.gig_data['dm_count_min'].dropna(), data.gig_data['dm_count_mean'].dropna(),\n",
    "                            data.gig_data['dm_count_max'].dropna()], label_3=\"Gigaword\"),\n",
    "                   [\"Min # DM\", \"Mean # DM\", \"Max # DM\"],\n",
    "                   \"# Markers per Sentence\",\n",
    "                   label_1=\"Spotify\", label_2=\"NYTimes\", label_3=\"Gigaword\",\n",
    "                   color_1='#1DB954', color_2='#cecece', color_3='#7CACED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of DM per Sentence - Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dm_per_sentence(data, title, color):\n",
    "    \"\"\"\n",
    "    Computes the number of DM per sentence and plots a histogram with a bar for each number of DM\n",
    "    :param data: dictionary with that contains the numbers of DMs as key and the number of sentences that contain the\n",
    "    respective number of DM as value\n",
    "    :param title: the title of the dataset\n",
    "    :param color: the color of the dataset (Spotify: '#1DB954', NYTimes: '#cecece', Gigaword: '#7CACED')\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    values = {}\n",
    "\n",
    "    '''\n",
    "    Scores are stored in one cell as a String, formated like a python dict\n",
    "    read the string and evaluate it like a pyton dict\n",
    "    '''\n",
    "    for doc in data:\n",
    "        doc_count = ast.literal_eval(doc)\n",
    "\n",
    "        for count in doc_count:\n",
    "            if count not in values:\n",
    "                values[count] = int(doc_count[count])\n",
    "            else:\n",
    "                values[count] += int(doc_count[count])\n",
    "\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "    for element in sorted(values.items()):\n",
    "        x_values.append(element[0])\n",
    "        y_values.append(element[1])\n",
    "\n",
    "    plt.style.use('fivethirtyeight')\n",
    "\n",
    "    plt.bar(x_values, y_values, color=color)\n",
    "    plt.xlabel(\"Number Marker per Sentence\")\n",
    "    plt.ylabel(\"Number Sentences\")\n",
    "\n",
    "    plt.title(\"Number of DM per Sentence - \" + title)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dm_per_sentence(data.spotify_data['dm_count_dict'].dropna(), \"Spotify\", '#1DB954')\n",
    "compute_dm_per_sentence(data.ny_data['dm_count_dict'].dropna(), \"New York Times\", '#cecece')\n",
    "compute_dm_per_sentence(data.gig_data['dm_count_dict'].dropna(), \"Gigaword\", '#7CACED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positions of Discourse Markers in the Sentences\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage(part, whole):\n",
    "    return (float(part) * 100) / (float(whole))\n",
    "\n",
    "\n",
    "def compute_percentages(values, data):\n",
    "    \"\"\"\n",
    "    Computes the percentages for an array of 3 values\n",
    "    :param values: the values to compute the percentage of\n",
    "    :param data:\n",
    "    :return: list of the three computed values\n",
    "    \"\"\"\n",
    "    whole = sum(values)\n",
    "    return [percentage(sum(data[0]), whole), percentage(sum(data[1]), whole),\n",
    "                  percentage(sum(data[2]), whole)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_yvalues_positions(data_1, label_1=None, data_2=None, label_2=None, data_3=None, label_3=None, data_4=None, label_4=None, perc=False):\n",
    "    \"\"\"\n",
    "    Computes the total number or percentage of DM at the beginning, middle or end of a sentence\n",
    "    data_x = [dm_pos_sent_begin, dm_pos_sent_middle, dm_pos_sent_end]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    y_values_1 = [sum(data_1[0]), sum(data_1[1]), sum(data_1[2])]\n",
    "    if perc:\n",
    "        y_values_1 = compute_percentages(y_values_1, data_1)\n",
    "        \n",
    "    y_values_2 = None\n",
    "    y_values_3 = None\n",
    "    y_values_4 = None\n",
    "    \n",
    "    values = {}\n",
    "    columns = ['Begin', 'Middle', 'End']\n",
    "    for key, value in zip(columns, y_values_1):\n",
    "        values[key] = [value]\n",
    "    values['Data'] = [label_1]\n",
    "\n",
    "    if data_2 is not None:\n",
    "        y_values_2 = [sum(data_2[0]), sum(data_2[1]), sum(data_2[2])]\n",
    "        if perc:\n",
    "            y_values_2 = compute_percentages(y_values_2, data_2)\n",
    "        values = add_values(values, columns, y_values_2, label_2)\n",
    "\n",
    "    if data_3 is not None:\n",
    "        y_values_3 = [sum(data_3[0]), sum(data_3[1]), sum(data_3[2])]\n",
    "        if perc:\n",
    "            y_values_3 = compute_percentages(y_values_3, data_3)\n",
    "        values = add_values(values, columns, y_values_3, label_3)\n",
    "\n",
    "    if data_4 is not None:\n",
    "        y_values_4 = [sum(data_4[0]), sum(data_4[1]), sum(data_4[2])]\n",
    "        if perc:\n",
    "            y_values_4 = compute_percentages(y_values_4, data_4)\n",
    "        values = add_values(values, columns, y_values_4, label_4)\n",
    "\n",
    "    print_dataframe(values, 'Data')\n",
    "    \n",
    "    return [y_values_1, y_values_2, y_values_3, y_values_4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Discourse Markers at a certain Position in a Sentence\n",
    "\n",
    "Shows how many Discourse Markers the sentences in the documents of a Dataset contain at the beginning, in the middle and at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_barchart(\"Number of DM at a certain Position in a Sentence\",\n",
    "                   compute_yvalues_positions(\n",
    "                       [data.spotify_data['dm_pos_sent_begin'].dropna(), data.spotify_data['dm_pos_sent_middle'].dropna(),\n",
    "                        data.spotify_data['dm_pos_sent_end'].dropna()], label_1=\"Spotify\",\n",
    "                       data_2=[data.ny_data['dm_pos_sent_begin'].dropna(), data.ny_data['dm_pos_sent_middle'].dropna(),\n",
    "                               data.ny_data['dm_pos_sent_end'].dropna()], label_2=\"NYTimes\",\n",
    "                       data_3=[data.gig_data['dm_pos_sent_begin'].dropna(), data.gig_data['dm_pos_sent_middle'].dropna(),\n",
    "                               data.gig_data['dm_pos_sent_end'].dropna()], label_3=\"Gigaword\"\n",
    "                   ),\n",
    "                   [\"begin\", \"middle\", \"end\"],\n",
    "                   \"# DM at Postion\",\n",
    "                   label_1=\"Spotify\", label_2=\"NYTimes\", label_3=\"Gigaword\",\n",
    "                   color_1='#1DB954', color_2='#cecece', color_3='#7CACED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of Discourse Markers at a certain Position in a Sentence\n",
    "\n",
    "Shows where the Discourse Markers are positioned in a sentence as a percentage (i.e. 'x% of the Discourse Markers of the Documents in Dataset A are positioned at the beginning of a sentence, y % in the middle and z% at the end of a sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_barchart(\"% of DM in a Position in a Sentence\",\n",
    "                   compute_yvalues_positions(\n",
    "                       [data.spotify_data['dm_pos_sent_begin'].dropna(), data.spotify_data['dm_pos_sent_middle'].dropna(),\n",
    "                        data.spotify_data['dm_pos_sent_end'].dropna()], label_1=\"Spotify\",\n",
    "                       data_2=[data.ny_data['dm_pos_sent_begin'].dropna(), data.ny_data['dm_pos_sent_middle'].dropna(),\n",
    "                               data.ny_data['dm_pos_sent_end'].dropna()], label_2=\"NYTimes\",\n",
    "                       data_3=[data.gig_data['dm_pos_sent_begin'].dropna(), data.gig_data['dm_pos_sent_middle'].dropna(),\n",
    "                               data.gig_data['dm_pos_sent_end'].dropna()], label_3=\"Gigaword\",\n",
    "                       perc=True\n",
    "                   ),\n",
    "                   [\"Sent. Begin\", \"Sent. Middle\", \"Sent. End\"],\n",
    "                   \"% DM at Postion\",\n",
    "                   label_1=\"Spotify\", label_2=\"NYTimes\", label_3=\"Gigaword\",\n",
    "                   color_1='#1DB954', color_2='#cecece', color_3='#7CACED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Piecharts that show how many Discourse Markers are positioned in the beginning, the middle and the end of the sentences in the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dm_positions_sent_piechart(title, data, labels, colors):\n",
    "    \"\"\"\n",
    "    Prepares the Data for Piecharts:\n",
    "    One for each Dataset with slices=[counter_begin, counter_middle, counder_end]\n",
    "    and one for each Position (Begin, Middle, End) with slices for each dataset\n",
    "    :param: data array that contains the datasets\n",
    "    :param: array of labels for the datasets\n",
    "    :param: array of colors for the datasets\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    set_labels = [\"Sentence Begin\", \"Sentence Middle\", \"Sentence End\"]\n",
    "    # greens, greys, blues\n",
    "    set_colors = [['#61D836', '#007B76', '#1DB100'], ['#f2f2f2', '#cecece', '#aba7a7'],\n",
    "                  ['#7CACED', '#2657AF', '#6291E7']]\n",
    "    begin_slices = []\n",
    "    middle_slices = []\n",
    "    end_slices = []\n",
    "    for dataset, label, color in zip(data, labels, set_colors):\n",
    "        begin_slices.append(sum(dataset[0]))\n",
    "        middle_slices.append(sum(dataset[1]))\n",
    "        end_slices.append(sum(dataset[2]))\n",
    "        set_slices = [sum(dataset[0]), sum(dataset[1]), sum(dataset[2])]\n",
    "        set_title = label\n",
    "        draw_piechart(set_title, set_slices, set_labels, color, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dm_positions_sent_piechart(\"Number of DM in a Sentence at Position:\",\n",
    "                                    [[data.spotify_data['dm_pos_sent_begin'].dropna(),\n",
    "                                      data.spotify_data['dm_pos_sent_middle'].dropna(),\n",
    "                                      data.spotify_data['dm_pos_sent_end'].dropna()],\n",
    "                                     [data.ny_data['dm_pos_sent_begin'].dropna(), data.ny_data['dm_pos_sent_middle'].dropna(),\n",
    "                                      data.ny_data['dm_pos_sent_end'].dropna()],\n",
    "                                     [data.gig_data['dm_pos_sent_begin'].dropna(), data.gig_data['dm_pos_sent_middle'].dropna(),\n",
    "                                      data.gig_data['dm_pos_sent_end'].dropna()]\n",
    "                                     ],\n",
    "                                    [\"Spotify Data\", \"NYTimes Data\", \"Gigaword Data\"],\n",
    "                                    ['#1DB954', '#cecece', '#7CACED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markerhäufigkeiten - generell\n",
    "Vertikal Barchart mit einem Balken pro Marker um dessen Häufigkeit im Datensatz zu zeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
